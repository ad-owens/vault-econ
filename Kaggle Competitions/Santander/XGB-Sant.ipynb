{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from sklearn import ensemble\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/boulenge/Desktop/Projects/Project4 - ML/train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bbad4d221dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Read train and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/boulenge/Desktop/Projects/Project4 - ML/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, header=None, skiprows = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/boulenge/Desktop/Projects/Project4 - ML/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, header=None, skiprows = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adamowens/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adamowens/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adamowens/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adamowens/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adamowens/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/boulenge/Desktop/Projects/Project4 - ML/train.csv does not exist"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Read train and test\n",
    "#####################\n",
    "train = pd.read_csv(\"/Users/boulenge/Desktop/Projects/Project4 - ML/train.csv\", sep=',',\\\n",
    "                        encoding='utf-8')#, header=None, skiprows = 1)\n",
    "train = train.set_index(\"ID\")\n",
    "test = pd.read_csv(\"/Users/boulenge/Desktop/Projects/Project4 - ML/test.csv\", sep=',',\\\n",
    "                        encoding='utf-8')#, header=None, skiprows = 1)\n",
    "test = test.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# Remove the similar features\n",
    "#############################\n",
    "Full_train = train.iloc[:, :369]\n",
    "temp = Full_train\n",
    "ind_same = {}\n",
    "for i in range(len(temp.columns)):\n",
    "    tp = temp.drop(temp.columns[i], inplace=False, axis=1)\n",
    "    for j in range(i+1, len(tp.columns)):\n",
    "        lst = reduce(lambda x, y: x + y, ind_same.values(), [])\n",
    "        if all(temp.iloc[:, i] == tp.iloc[:, j]):\n",
    "            if i not in ind_same.keys():\n",
    "                if i not in lst:\n",
    "                    if j >= i: ind_same[i] = [j+1]\n",
    "                    else: ind_same[i] = [j]\n",
    "            else:\n",
    "                if j >= i: ind_same[i].append(j+1)\n",
    "                else: ind_same[i].append(j)\n",
    "\n",
    "print \"Full_train shape before dropping similar features: \" + str(Full_train.shape)\n",
    "ind_drop = reduce(lambda x, y: x + y, ind_same.values(), [])                 \n",
    "Full_train.drop(Full_train.columns[ind_drop], inplace=True, axis=1)\n",
    "print \"Full_train shape after: \" + str(Full_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Full_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3bb64977e85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## adding the column TARGET to investigate the rows in Full_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFull_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m## finding out behavior of features' outliers in temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprop_1_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_1_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ind_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ind_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Full_train' is not defined"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Outliers\n",
    "################################\n",
    "## adding the column TARGET to investigate the rows in Full_train\n",
    "temp = pd.concat([Full_train, train['TARGET']], axis=1)\n",
    "## finding out behavior of features' outliers in temp\n",
    "prop_1_max, prop_1_min, row_ind_max, row_ind_min, feature = [], [], [], [], []\n",
    "for name in Full_train.columns:\n",
    "    col_max = temp[temp[name] == max(temp[name])]['TARGET']\n",
    "    col_min = temp[temp[name] == min(temp[name])]['TARGET']\n",
    "    val_max, val_min = np.mean(col_max), np.mean(col_min)\n",
    "    prop_1_max.append(val_max)\n",
    "    row_ind_max.append(Full_train.index[np.where(temp[name] == max(temp[name]))])\n",
    "    prop_1_min.append(val_min)\n",
    "    row_ind_min.append(Full_train.index[np.where(temp[name] == min(temp[name]))])\n",
    "    feature.append(name)\n",
    "    \n",
    "prop_1 = pd.DataFrame({'Max': prop_1_max, 'Min': prop_1_min, 'row_ind_max': row_ind_max, \\\n",
    "                      'row_ind_min': row_ind_min, 'feature': feature})\n",
    "print \"Number of features for which only 1s hit the max: \" \\\n",
    "                 + str(len(prop_1[prop_1.Max == 1]['Max']))\n",
    "print \"Number of features for which only 0s hit the max: \" \\\n",
    "                 + str(len(prop_1[prop_1.Max == 0]['Max']))\n",
    "print \"Number of features for which at least one 1 hit the min: \" \\\n",
    "                 + str(len(prop_1[prop_1.Min != 0]['Min']))\n",
    "print \"Full_train shape: \" + str(Full_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prop_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8498141cffb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## when the TARGET HAS to be 0 and the outlier is isolated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrow_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_ind_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0misol_out0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mrow_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfeat0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misol_out0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prop_1' is not defined"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Max Outliers\n",
    "################################\n",
    "## when the TARGET HAS to be 0 and the outlier is isolated\n",
    "row_out = [len(l) == 1 for l in prop_1.row_ind_max]\n",
    "isol_out0 = prop_1[(prop_1.Max == 0) & row_out]\n",
    "feat0 = isol_out0.feature\n",
    "row_feat_out0 = [x[0] for x in isol_out0.row_ind_max]\n",
    "\n",
    "new_col_0_out = pd.Series(np.zeros(len(Full_train)), index = Full_train.index)\n",
    "\n",
    "for row in row_feat_out0:\n",
    "    if row in new_col_0_out.index:\n",
    "        new_col_0_out[row] = 1\n",
    "    else: print \"Nope\"\n",
    "print len(new_col_0_out)\n",
    "#new_col_0_out = pd.Series(new_col_0_out, index = Full_train.index)\n",
    "\n",
    "for row, col in zip(row_feat_out0, feat0):\n",
    "    Full_train.loc[row, col] = 0 ## set outliers to zero\n",
    "    \n",
    "Full_train = pd.concat([Full_train, pd.DataFrame({'Out_1': new_col_0_out})], axis=1)\n",
    "\n",
    "## when the TARGET HAS to be 1 and the outlier is isolated\n",
    "isol_out1 = prop_1[(prop_1.Max == 1) & row_out]\n",
    "feat1 = isol_out1.feature\n",
    "row_feat_out1 = [x[0] for x in isol_out1.row_ind_max]\n",
    "\n",
    "new_col_1_out = pd.Series(np.zeros(len(Full_train)), index = Full_train.index)\n",
    "for row in row_feat_out1:\n",
    "    if row in new_col_1_out.index:\n",
    "        new_col_1_out[row] = 1\n",
    "    else: print \"Nope\"\n",
    "#new_col_1_out = pd.Series(new_col_1_out, index = Full_train.index)\n",
    "\n",
    "for row, col in zip(row_feat_out1, feat1):\n",
    "    Full_train.loc[row, col] = 0 ## set outliers to zero\n",
    "    \n",
    "Full_train = pd.concat([Full_train, pd.DataFrame({'Out_2': new_col_1_out})], axis=1)\n",
    "    \n",
    "Full_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Full_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fbcbe3ed63df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Normalize train (with no target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mFull_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFull_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#Full_train.to_csv(\"/Users/boulenge/Desktop/Projects/Project4 - ML/Full_train.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m369\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Full_train' is not defined"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Normalize train (with no target)\n",
    "##################################\n",
    "Full_train = min_max_scaler.fit_transform(Full_train)\n",
    "#Full_train.to_csv(\"/Users/boulenge/Desktop/Projects/Project4 - ML/Full_train.csv\")\n",
    "train_target = train.iloc[:, 369]\n",
    "\n",
    "# Normalize test\n",
    "Full_test = test\n",
    "Full_test = min_max_scaler.fit_transform(Full_test)\n",
    "Full_test = pd.DataFrame(Full_test, index = test.index)\n",
    "#Full_test.to_csv(\"/Users/boulenge/Desktop/Projects/Project4 - ML/Full_test.csv\")\n",
    "\n",
    "######### Full train ##################\n",
    "## Slow CV on Full train set\n",
    "# Cross-Validation and evaluate_model: 75% train - 25% test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "             cv.train_test_split(Full_train, train_target, test_size=0.25, random_state=0, \\\n",
    "                                 stratify = train_target)\n",
    "\n",
    "\n",
    "def evaluate_model(clf):\n",
    "    \"\"\"Scores a model using log loss with the created train and test sets.\"\"\"\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print \"Train score:\", sklearn.metrics.roc_auc_score(y_train, clf.predict_proba(X_train)[:,1])\n",
    "    print \"Test score:\", sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    print \"Total time:\", time.time() - start\n",
    "\n",
    "print \"Full Training: \" + str(X_train.shape) + str(y_train.shape)\n",
    "print \"Full Test: \" + str(X_test.shape) + str(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 models to test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec2fb70a43a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mxgb_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Auto Grid search\n",
    "################################\n",
    "\n",
    "#param = {'max_depth': [10, 11, 12], \\\n",
    "#         'n_estimators': [49, 50, 51], \\\n",
    "#         'min_child_weight': [1, 2], \\\n",
    "#         'colsample_bytree': [0.65, 0.7, 0.75],\n",
    "#         'base_score': [0.25, 0.3, 0.35], \\\n",
    "#         'learning_rate': [0.05, 0.1, 0.15], \\\n",
    "#         'scale_pos_weight': [1],\n",
    "#         'nthread': [1],\n",
    "#         'reg_lambda': [0, 1, 5],\n",
    "#         'scale_pos_weight': [1, 10, 15, 20]\n",
    "#         }\n",
    "\n",
    "#param = {'max_depth': [10], \\\n",
    "#         'n_estimators': [50], \\\n",
    "#         'min_child_weight': [1], \\\n",
    "#         'colsample_bytree': np.arange(0.735, 0.745, 0.001),\n",
    "#         'base_score': np.arange(0.295, 0.305, 0.001), \\\n",
    "#         'learning_rate': np.arange(0.1, 0.115, 0.001), \\\n",
    "#         'scale_pos_weight': np.arange(0.1, 1.5, 0.1),\n",
    "#         'nthread': [1],\n",
    "#         'reg_lambda': [1],\n",
    "#         }\n",
    "\n",
    "param = {'max_depth': range(9, 11), \\\n",
    "         'n_estimators': [50], \\\n",
    "         'min_child_weight': [1], \\\n",
    "         'colsample_bytree': [0.7],\n",
    "         'base_score': [0.29, 0.3], \\\n",
    "         'learning_rate': np.arange(0.09, 0.11, 0.01), \\\n",
    "         'scale_pos_weight': [1],\n",
    "         'nthread': [1],\n",
    "         'reg_lambda': [1], \\\n",
    "         'reg_alpha': [4], \\\n",
    "         'max_delta_step': np.arange(0, 3, 1)\n",
    "         }\n",
    "\n",
    "print str(np.product([len(param[x]) for x in param])) + \" models to test\"\n",
    "\n",
    "xgb_mod = XGBClassifier(objective='binary:logistic')\n",
    "clf = GridSearchCV(xgb_mod, param, verbose=2, scoring='roc_auc', cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
