{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "In [1]:\n",
    "rom __future__ import division\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "def bicluster(i,j):\n",
    "    tix = np.array(trainpart['hotel_cluster'].values==i)+np.array(trainpart['hotel_cluster'].values==j)\n",
    "    tGBtraintarget = (trainpart['hotel_cluster'].values==i)*1\n",
    "    tGBpara = {'data':GBdata,'feature_names':featurelist,'target':tGBtraintarget,\n",
    "    'target_names':np.arange(100)}\n",
    "    tmp = tGBpara['target'][tix]\n",
    "    if sum(tmp==0)==0:\n",
    "        tmp[-1] = 0\n",
    "    tclf = GradientBoostingClassifier(n_estimators=20, learning_rate=1,\n",
    "    max_depth=2, random_state=0).fit(GBdata[tix], tmp)\n",
    "    return tclf\n",
    "\n",
    "def oneclus(n):\n",
    "    if n<99:\n",
    "        return bicluster(n,n+1)\n",
    "    else:\n",
    "        return bicluster(n,0)\n",
    "    \n",
    "def getvoter():\n",
    "    voterlist = []\n",
    "    for i in range(100):\n",
    "        accuracy = []\n",
    "        clflist = []\n",
    "        clf  = oneclus(i)\n",
    "        clflist.append(clf)\n",
    "        for j in range(100):\n",
    "            tix = np.array(testpart1['hotel_cluster'].values==i)+np.array(testpart1['hotel_cluster'].values==j)\n",
    "            accuracy.append( clf.score(testdata1[tix], 1*(testpart1['hotel_cluster'][tix].values==i)) )  \n",
    "            #must use a testdata that contains true clusters\n",
    "        accuracy = DataFrame([accuracy],index = ['accuracy']).T\n",
    "        clusix = accuracy.sort_values( by ='accuracy',ascending = True).index[:4]\n",
    "        tclf = clf\n",
    "        for ind in clusix:\n",
    "            tclf = bicluster(i,ind)    \n",
    "            clflist.append(tclf)\n",
    "        voterlist.append(clflist)\n",
    "    return voterlist\n",
    "    \n",
    "def GBvote(testdata,voterlist):\n",
    "    clusprob = []\n",
    "    now = datetime.datetime.now()\n",
    "    path = 'submission_GB_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    out = open(path, \"w\")\n",
    "    out.write(\"id,hotel_cluster\\n\")\n",
    "    m = len(voterlist[0])\n",
    "    for i in range(100):\n",
    "        print('1----'+str(i))\n",
    "        clflist = voterlist[i]\n",
    "        tmp = np.zeros([len(testdata),2])\n",
    "        for j in range(m):    #compute the probability given by evevey clf\n",
    "            clf = clflist[j]\n",
    "            tmp = tmp + clf.predict_proba(testdata)\n",
    "        tmp = tmp/m    \n",
    "        tmp = (tmp[:,1]>0.5)*tmp[:,1]    #total probability for belonging to cluster i\n",
    "        clusprob.append(tmp)\n",
    "    clusprob = np.array(clusprob)\n",
    "    for i in range(len(testdata)):\n",
    "        if i%20000 == 0:\n",
    "            print('2----'+str(i))\n",
    "        clus = []\n",
    "        a = clusprob[:,i]\n",
    "        b=np.argsort(a)[-5:]\n",
    "        #clusprob.drop(i,axis = 1)\n",
    "        for ind in b:\n",
    "            clus.append(str(ind))\n",
    "        out.write(str(i)+\",\"+\"\\t\".join(clus)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "file = open(\"../input/train.csv\")\n",
    "fout = open('subset_datatest.csv','w')\n",
    "n = 0\n",
    "for line in file:\n",
    "    if n == 0:\n",
    "        fout.write(line)\n",
    "    if n <400000*5:\n",
    "        n +=1\n",
    "    elif 400000*5<=n <400000*10:\n",
    "        n +=1\n",
    "        fout.write(line)\n",
    "    else:\n",
    "        break\n",
    "fout.close()\n",
    "file.close()\n",
    "file = open(\"../input/train.csv\")\n",
    "fout = open('subset_datatrain.csv','w')\n",
    "n = 0\n",
    "for line in file:\n",
    "    if n <400000*5:\n",
    "        n +=1\n",
    "        fout.write(line)\n",
    "    else:\n",
    "        break\n",
    "fout.close()\n",
    "file.close()\n",
    "In [3]:\n",
    "dategroup = ['2013Jan','2013May','2013Sep','2014Jan','2014May','2014Sep','2015Jan','2015May','2015Sep']\n",
    "chingroup = ['2013Jan','2013May','2013Sep','2014Jan','2014May','2014Sep','2015Jan','2015May','2015Sep']\n",
    "dateix = [[] for i in range(9)]\n",
    "chinix = [[] for i in range(9)]\n",
    "timeframe = pd.read_csv('subset_datatest.csv',na_values=['--  '],usecols = ['date_time','srch_ci'])\n",
    "datetime = pd.to_datetime(timeframe['date_time'].values)\n",
    "datetime = Series(np.arange(len(datetime)),index = datetime)\n",
    "for i in range(36):\n",
    "    y = divmod(i,12)[0]\n",
    "    r = divmod(i,12)[1]\n",
    "    n = divmod(i,4)[0]\n",
    "    if r<9:\n",
    "        dateix[n].extend(datetime['201'+str(3+y)+'-0'+str(r+1)].values)\n",
    "    else:\n",
    "        dateix[n].extend(datetime['201'+str(3+y)+'-'+str(r+1)].values)\n",
    "\n",
    "        \n",
    "chinix = [[] for i in range(9)]\n",
    "citime = pd.to_datetime(timeframe['srch_ci'].values)\n",
    "citime = Series(np.arange(len(citime)),index = citime)\n",
    "for i in range(36):\n",
    "    y = divmod(i,12)[0]\n",
    "    r = divmod(i,12)[1]\n",
    "    n = divmod(i,4)[0]\n",
    "    if r<9:\n",
    "        chinix[n].extend(citime['201'+str(3+y)+'-0'+str(r+1)].values)\n",
    "    else:\n",
    "        chinix[n].extend(citime['201'+str(3+y)+'-'+str(r+1)].values)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NameError: name 'pd' is not defined\n",
    "In [6]:\n",
    "timeframe2 = pd.read_csv('subset_datatrain.csv',na_values=['--  '],usecols = ['date_time','srch_ci'])\n",
    "chinix2 = [[] for i in range(9)]\n",
    "citime2 = pd.to_datetime(timeframe2['srch_ci'].values)\n",
    "citime2 = Series(np.arange(len(citime2)),index = citime2)\n",
    "for i in range(36):\n",
    "    y = divmod(i,12)[0]\n",
    "    r = divmod(i,12)[1]\n",
    "    n = divmod(i,4)[0]\n",
    "    if r<9:\n",
    "        chinix2[n].extend(citime2['201'+str(3+y)+'-0'+str(r+1)].values)\n",
    "    else:\n",
    "        chinix2[n].extend(citime2['201'+str(3+y)+'-'+str(r+1)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeframe2 = pd.read_csv('subset_datatrain.csv',na_values=['--  '],usecols = ['date_time','srch_ci'])\n",
    "chinix2 = [[] for i in range(9)]\n",
    "citime2 = pd.to_datetime(timeframe2['srch_ci'].values)\n",
    "citime2 = Series(np.arange(len(citime2)),index = citime2)\n",
    "for i in range(36):\n",
    "    y = divmod(i,12)[0]\n",
    "    r = divmod(i,12)[1]\n",
    "    n = divmod(i,4)[0]\n",
    "    if r<9:\n",
    "        chinix2[n].extend(citime2['201'+str(3+y)+'-0'+str(r+1)].values)\n",
    "    else:\n",
    "        chinix2[n].extend(citime2['201'+str(3+y)+'-'+str(r+1)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "featurelist = ['user_location_city','srch_destination_id','hotel_continent','srch_ci']\n",
    "whlist = ['user_location_city','srch_destination_id','hotel_continent','srch_ci','hotel_cluster']\n",
    "trainpart = pd.read_csv('subset_datatrain.csv',na_values=['--  '],usecols = whlist)\n",
    "for i in range(9):\n",
    "    trainpart['srch_ci'].values[chinix2[i]] = i\n",
    "GBdata = trainpart[featurelist].values\n",
    "GBpara = {'data':GBdata,'feature_names':featurelist,'target':trainpart['hotel_cluster'].values,\n",
    "'target_names':np.arange(100)}\n",
    "\n",
    "testpart = pd.read_csv('../input/test.csv',na_values=['--  '],usecols = featurelist)\n",
    "for i in range(9):\n",
    "    testpart['srch_ci'].values[chinix[i]] = i\n",
    "testdata = testpart[featurelist].values\n",
    "testpart1 = pd.read_csv('subset_datatest.csv',na_values=['--  '],usecols = whlist)\n",
    "testdata1 = testpart1[featurelist].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voterlist = getvoter()\n",
    "del testpart1\n",
    "del testdata1\n",
    "del GBdata\n",
    "del GBpara\n",
    "del trainpart\n",
    "del testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = testpart.values\n",
    "clusprob = []\n",
    "now = datetime.datetime.now()\n",
    "path = 'submission_GB_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "out = open(path, \"w\")\n",
    "out.write(\"id,hotel_cluster\\n\")\n",
    "m = len(voterlist[0])\n",
    "for i in range(100):\n",
    "    print('1----'+str(i))\n",
    "    clflist = voterlist[i]\n",
    "    tmp = np.zeros([len(testdata),2])\n",
    "    for j in range(m):    #compute the probability given by evevey clf\n",
    "        clf = clflist[j]\n",
    "        tmp = tmp + clf.predict_proba(testdata)\n",
    "    tmp = tmp/m    \n",
    "    tmp = (tmp[:,0]>0.5)*tmp[:,0]    #total probability for belonging to cluster i\n",
    "    clusprob.append(tmp)\n",
    "clusprob = np.array(clusprob)\n",
    "for i in range(len(testdata)):\n",
    "    if i%1000 == 0:\n",
    "        print('2----'+str(i))\n",
    "    clus = []\n",
    "    a = DataFrame(clusprob[:,i])\n",
    "    b=a.sort_values(by = 0,ascending = False).index[:5]\n",
    "    #clusprob.drop(i,axis = 1)\n",
    "    for ind in b:\n",
    "        clus.append(str(ind))\n",
    "    out.write(str(i)+\",\"+\"\\t\".join(clus)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(testdata)):\n",
    "    if i%1000 == 0:\n",
    "        print('2----'+str(i))\n",
    "    clus = []\n",
    "    a = DataFrame(clusprob[:,i])\n",
    "    b=a.sort_index(by = 0,ascending = False).index[:5]\n",
    "    #clusprob.drop(i,axis = 1)\n",
    "    for ind in b:\n",
    "        clus.append(str(ind))\n",
    "    out.write(str(i)+\",\"+\"\\t\".join(clus)+\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
